{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e1d5da",
   "metadata": {},
   "source": [
    "### RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6faf5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5db1ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    \n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(pdf_files)\n",
    "    \n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "            \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"  ✓ Loaded {len(documents)} pages\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed55be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../data/pdf_files/Mullayanagiri_FEUPIUFACCA18CCCE.pdf'), PosixPath('../data/pdf_files/k_kanishkar_resume.pdf')]\n",
      "Found 2 PDF files to process\n",
      "\n",
      "Processing: Mullayanagiri_FEUPIUFACCA18CCCE.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Processing: k_kanishkar_resume.pdf\n",
      "  ✓ Loaded 1 pages\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "# Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d306218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "    \n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c61c8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2 documents into 5 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Kanishkar  K\n",
      " \n",
      "kanishkar51015@gmail.com |  +91  9043222010  |  LinkedIn |  GitHub  \n",
      "ABOUT  \n",
      " \n",
      " \n",
      "Software  Engineer  with  3+  years  of  experience  building  data  pipelines,  analytical  dashboards,...\n",
      "Metadata: {'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='Kanishkar  K\\n \\nkanishkar51015@gmail.com |  +91  9043222010  |  LinkedIn |  GitHub  \\nABOUT  \\n \\n \\nSoftware  Engineer  with  3+  years  of  experience  building  data  pipelines,  analytical  dashboards,  and  backend  systems  for  operational  \\nand\\n \\nanalytical\\n \\nuse\\n \\ncases.\\n \\nSkilled\\n \\nin\\n \\nPython,\\n \\nJavascript,\\n \\nPostgreSQL,\\n \\nRetool\\n \\nwith\\n \\na\\n \\nstrong\\n \\nfocus\\n \\non\\n \\nperformance\\n \\nand\\n \\nreliability.\\n \\nPassionate\\n \\nabout\\n \\nsolving\\n \\nreal-world\\n \\nproblems\\n \\nthrough\\n \\ntechnology\\n \\nand\\n \\ncontinuously\\n \\nlearning.\\n  \\nEDUCATION  \\n \\n \\nSRM  INSTITUTE  OF  SCIENCE  AND  TECHNOLOGY Chennai,  India  Bachelor  of  Technology May  2022 Major  in  Computer  Science;  Specialization  in  Artificial  Intelligence,  and  Machine  Learning.   Cumulative  GPA:  9.82/10   \\nWORK  EXPERIENCE'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='WORK  EXPERIENCE  \\n \\n \\nFoundation  AI Hyderabad,  India  Software  Engineer  Sep  2024  –  Present  ●  Designed  and  maintained  dashboards  and  automated  workflows  using  Python,  FastAPI,  PostgreSQL ,  and  Retool  to  support  \\nclient\\n \\nonboarding\\n \\nand\\n \\noperational\\n \\nanalytics,\\n \\nreducing\\n \\nonboarding\\n \\ntime\\n \\nby\\n \\nover\\n \\n80%\\n.\\n ●  Built  data  validation  and  analytics  dashboards  to  analyze  model  outputs,  track  performance  metrics,  and  support  continuous  \\nimprovement\\n \\nof\\n \\nproduction\\n \\nsystems.\\n ●  Worked  with  cross-functional  teams  to  design  and  deliver  internal  tools,  while  mentoring  two  engineers  in  developing  scalable  \\nsolutions\\n \\nusing\\n \\nFastAPI\\n,\\n \\nReact.js\\n,\\n \\nand\\n \\nRetool\\n.\\n  \\nNova  Benefits Bangalore,  India  Solutions  Engineer  May  2022  –  Sep  2024  ●  Built  backend  services  leveraging  Generative  AI  to  process  client  conversations  across  multiple  channels  (Email,  Slack,  \\nWhatsApp,\\n \\nGoogle\\n \\nMeet)\\n \\nand\\n \\nproduce'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='WhatsApp,\\n \\nGoogle\\n \\nMeet)\\n \\nand\\n \\nproduce\\n \\nactionable\\n \\nsummaries\\n \\nand\\n \\nfeedback\\n \\nfor\\n \\nexecutives.\\n ●  Developed  a  Node.js -based  data  processing  dashboard  integrated  with  Retool  to  automate  insurance  and  employee  data  \\nvalidation,\\n \\nclient\\n \\ncommunication,\\n \\nand\\n \\nreporting\\n \\nworkflows,\\n \\nreducing\\n \\nprocessing\\n \\ntime\\n \\nby\\n \\n5\\n \\ndays\\n.\\n ●  Built  and  deployed  WhatsApp  and  email-based  automation  workflows  to  streamline  client  communication  processes,  \\nimproving\\n \\nengagement\\n \\nrates\\n \\nby\\n \\n20%\\n.\\n ●  Developed  custom  onboarding  workflows  by  connecting  backend  logic  with  dynamic  frontend  components  in  Retool ,  \\nimproving\\n \\nusability\\n \\nand\\n \\ndriving\\n \\na\\n \\n15%\\n \\nincrease\\n \\nin\\n \\nclient\\n \\nretention.\\n ●  Developed  data  pipelines  integrating  Google  Forms ,  Tally ,  and  Webflow  sources  into  centralized  dashboards,  improving  \\nvisibility\\n \\nand\\n \\nstreamlining\\n \\nlead\\n \\ntracking\\n \\nworkflows.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='visibility\\n \\nand\\n \\nstreamlining\\n \\nlead\\n \\ntracking\\n \\nworkflows.\\n ●  Developed  Python-based  ETL  pipelines  using  Pandas  and  NumPy  to  extract,  transform,  and  load  data  from  client  websites,  \\nZoho\\n \\nCRM,\\n \\nand\\n \\nGoogle\\n \\nSheets\\n \\ninto\\n \\nanalytical\\n \\ndashboards,\\n \\nenhancing\\n \\noperational\\n \\nvisibility\\n \\nand\\n \\nworkflow\\n \\nefficiency.\\n  \\nPROJECTS  \\n \\n \\nKnowledge  Base  Assistant  July  2025  Developed  an  AI-powered  knowledge  assistant  integrating  LangChain ,  OpenAI  API ,  and  Retool ,  enabling  employees  to  query  \\norganizational\\n \\ndata\\n \\nfrom\\n \\nGoogle\\n \\nDrive\\n,\\n \\nJira\\n,\\n \\nand\\n \\nConfluence\\n \\nthrough\\n \\na\\n \\nunified\\n \\ninterface.\\n  \\nImmigrant  Housing  Finder  Jan  2022  Developed  a  data-driven  recommendation  system  using  the  Foursquare  API  to  analyze  geolocation  data  and  match  \\naccommodation\\n \\noptions\\n \\nwith\\n \\nuser-defined\\n \\npreferences.\\n \\nImplemented\\n \\nwith\\n \\nStreamlit\\n,\\n \\nPandas\\n,\\n \\nand\\n \\nMatplotlib\\n.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='accommodation\\n \\noptions\\n \\nwith\\n \\nuser-defined\\n \\npreferences.\\n \\nImplemented\\n \\nwith\\n \\nStreamlit\\n,\\n \\nPandas\\n,\\n \\nand\\n \\nMatplotlib\\n.\\n  \\nPublication  -  Deeply  Supervised  Video  Violence  Detection  Feb  2022  “Deeply  Supervised  Practical  Implementation  of  Violence  Detection  from  Videos  for  Maximising  Performance”  —  proposed  a  low-complexity  \\napproach\\n \\nusing\\n \\npre-trained\\n \\ndeep\\n \\nneural\\n \\nnetworks\\n \\nto\\n \\nefficiently\\n \\ndetect\\n \\nand\\n \\nclassify\\n \\nviolent\\n \\nactions\\n \\nin\\n \\nsurveillance\\n \\nfootage.\\n  \\nSKILLS  \\n \\n \\nLanguages  &  Frameworks :  JavaScript  (NodeJS,  ReactJS),  Python  (FastAPI,  Django,  Streamlit,  TensorFlow,  Scikit-learn,  Pandas,  \\nNumPy,\\n \\nMatplotlib),\\n \\nC,\\n \\nC++\\n Databases:  PostgreSQL,  MongoDB  Tools:  AWS,  Docker,  Git,  GitHub,  Postman,  Retool,  N8N,  Zapier,  Airtable,  Apps  Script  APIs:  REST,  GraphQL')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55e1ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6f7ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x165087610>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using SentenceTransformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "## initialize the embedding manager\n",
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcf36b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x17ff02ef0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistent ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        \n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            # Prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        \n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore=VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46b7db25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='Kanishkar  K\\n \\nkanishkar51015@gmail.com |  +91  9043222010  |  LinkedIn |  GitHub  \\nABOUT  \\n \\n \\nSoftware  Engineer  with  3+  years  of  experience  building  data  pipelines,  analytical  dashboards,  and  backend  systems  for  operational  \\nand\\n \\nanalytical\\n \\nuse\\n \\ncases.\\n \\nSkilled\\n \\nin\\n \\nPython,\\n \\nJavascript,\\n \\nPostgreSQL,\\n \\nRetool\\n \\nwith\\n \\na\\n \\nstrong\\n \\nfocus\\n \\non\\n \\nperformance\\n \\nand\\n \\nreliability.\\n \\nPassionate\\n \\nabout\\n \\nsolving\\n \\nreal-world\\n \\nproblems\\n \\nthrough\\n \\ntechnology\\n \\nand\\n \\ncontinuously\\n \\nlearning.\\n  \\nEDUCATION  \\n \\n \\nSRM  INSTITUTE  OF  SCIENCE  AND  TECHNOLOGY Chennai,  India  Bachelor  of  Technology May  2022 Major  in  Computer  Science;  Specialization  in  Artificial  Intelligence,  and  Machine  Learning.   Cumulative  GPA:  9.82/10   \\nWORK  EXPERIENCE'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='WORK  EXPERIENCE  \\n \\n \\nFoundation  AI Hyderabad,  India  Software  Engineer  Sep  2024  –  Present  ●  Designed  and  maintained  dashboards  and  automated  workflows  using  Python,  FastAPI,  PostgreSQL ,  and  Retool  to  support  \\nclient\\n \\nonboarding\\n \\nand\\n \\noperational\\n \\nanalytics,\\n \\nreducing\\n \\nonboarding\\n \\ntime\\n \\nby\\n \\nover\\n \\n80%\\n.\\n ●  Built  data  validation  and  analytics  dashboards  to  analyze  model  outputs,  track  performance  metrics,  and  support  continuous  \\nimprovement\\n \\nof\\n \\nproduction\\n \\nsystems.\\n ●  Worked  with  cross-functional  teams  to  design  and  deliver  internal  tools,  while  mentoring  two  engineers  in  developing  scalable  \\nsolutions\\n \\nusing\\n \\nFastAPI\\n,\\n \\nReact.js\\n,\\n \\nand\\n \\nRetool\\n.\\n  \\nNova  Benefits Bangalore,  India  Solutions  Engineer  May  2022  –  Sep  2024  ●  Built  backend  services  leveraging  Generative  AI  to  process  client  conversations  across  multiple  channels  (Email,  Slack,  \\nWhatsApp,\\n \\nGoogle\\n \\nMeet)\\n \\nand\\n \\nproduce'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='WhatsApp,\\n \\nGoogle\\n \\nMeet)\\n \\nand\\n \\nproduce\\n \\nactionable\\n \\nsummaries\\n \\nand\\n \\nfeedback\\n \\nfor\\n \\nexecutives.\\n ●  Developed  a  Node.js -based  data  processing  dashboard  integrated  with  Retool  to  automate  insurance  and  employee  data  \\nvalidation,\\n \\nclient\\n \\ncommunication,\\n \\nand\\n \\nreporting\\n \\nworkflows,\\n \\nreducing\\n \\nprocessing\\n \\ntime\\n \\nby\\n \\n5\\n \\ndays\\n.\\n ●  Built  and  deployed  WhatsApp  and  email-based  automation  workflows  to  streamline  client  communication  processes,  \\nimproving\\n \\nengagement\\n \\nrates\\n \\nby\\n \\n20%\\n.\\n ●  Developed  custom  onboarding  workflows  by  connecting  backend  logic  with  dynamic  frontend  components  in  Retool ,  \\nimproving\\n \\nusability\\n \\nand\\n \\ndriving\\n \\na\\n \\n15%\\n \\nincrease\\n \\nin\\n \\nclient\\n \\nretention.\\n ●  Developed  data  pipelines  integrating  Google  Forms ,  Tally ,  and  Webflow  sources  into  centralized  dashboards,  improving  \\nvisibility\\n \\nand\\n \\nstreamlining\\n \\nlead\\n \\ntracking\\n \\nworkflows.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='visibility\\n \\nand\\n \\nstreamlining\\n \\nlead\\n \\ntracking\\n \\nworkflows.\\n ●  Developed  Python-based  ETL  pipelines  using  Pandas  and  NumPy  to  extract,  transform,  and  load  data  from  client  websites,  \\nZoho\\n \\nCRM,\\n \\nand\\n \\nGoogle\\n \\nSheets\\n \\ninto\\n \\nanalytical\\n \\ndashboards,\\n \\nenhancing\\n \\noperational\\n \\nvisibility\\n \\nand\\n \\nworkflow\\n \\nefficiency.\\n  \\nPROJECTS  \\n \\n \\nKnowledge  Base  Assistant  July  2025  Developed  an  AI-powered  knowledge  assistant  integrating  LangChain ,  OpenAI  API ,  and  Retool ,  enabling  employees  to  query  \\norganizational\\n \\ndata\\n \\nfrom\\n \\nGoogle\\n \\nDrive\\n,\\n \\nJira\\n,\\n \\nand\\n \\nConfluence\\n \\nthrough\\n \\na\\n \\nunified\\n \\ninterface.\\n  \\nImmigrant  Housing  Finder  Jan  2022  Developed  a  data-driven  recommendation  system  using  the  Foursquare  API  to  analyze  geolocation  data  and  match  \\naccommodation\\n \\noptions\\n \\nwith\\n \\nuser-defined\\n \\npreferences.\\n \\nImplemented\\n \\nwith\\n \\nStreamlit\\n,\\n \\nPandas\\n,\\n \\nand\\n \\nMatplotlib\\n.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m145 Google Docs Renderer', 'creator': 'PyPDF', 'creationdate': '', 'title': 'Kanishkar_resume_quant', 'source': '../data/pdf_files/k_kanishkar_resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'source_file': 'k_kanishkar_resume.pdf', 'file_type': 'pdf'}, page_content='accommodation\\n \\noptions\\n \\nwith\\n \\nuser-defined\\n \\npreferences.\\n \\nImplemented\\n \\nwith\\n \\nStreamlit\\n,\\n \\nPandas\\n,\\n \\nand\\n \\nMatplotlib\\n.\\n  \\nPublication  -  Deeply  Supervised  Video  Violence  Detection  Feb  2022  “Deeply  Supervised  Practical  Implementation  of  Violence  Detection  from  Videos  for  Maximising  Performance”  —  proposed  a  low-complexity  \\napproach\\n \\nusing\\n \\npre-trained\\n \\ndeep\\n \\nneural\\n \\nnetworks\\n \\nto\\n \\nefficiently\\n \\ndetect\\n \\nand\\n \\nclassify\\n \\nviolent\\n \\nactions\\n \\nin\\n \\nsurveillance\\n \\nfootage.\\n  \\nSKILLS  \\n \\n \\nLanguages  &  Frameworks :  JavaScript  (NodeJS,  ReactJS),  Python  (FastAPI,  Django,  Streamlit,  TensorFlow,  Scikit-learn,  Pandas,  \\nNumPy,\\n \\nMatplotlib),\\n \\nC,\\n \\nC++\\n Databases:  PostgreSQL,  MongoDB  Tools:  AWS,  Docker,  Git,  GitHub,  Postman,  Retool,  N8N,  Zapier,  Airtable,  Apps  Script  APIs:  REST,  GraphQL')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cb25ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 5 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (5, 384)\n",
      "Adding 5 documents to vector store...\n",
      "Error adding documents to vector store: Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m embeddings\u001b[38;5;241m=\u001b[39membedding_manager\u001b[38;5;241m.\u001b[39mgenerate_embeddings(texts)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m##store int he vector dtaabase\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 75\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, embeddings)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Add to collection\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments_text\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully added \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents to vector store\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal documents in collection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Projects/personal/Personal_Project/rag_crash_course/.venv/lib/python3.10/site-packages/chromadb/api/models/Collection.py:97\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m add_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_add_request(\n\u001b[1;32m     89\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m     90\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muris\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Projects/personal/Personal_Project/rag_crash_course/.venv/lib/python3.10/site-packages/chromadb/api/rust.py:441\u001b[0m, in \u001b[0;36mRustBindingsAPI._add\u001b[0;34m(self, ids, collection_id, embeddings, metadatas, documents, uris, tenant, database)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_add\u001b[39m(\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[1;32m    432\u001b[0m         CollectionAddEvent(\n\u001b[1;32m    433\u001b[0m             collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    438\u001b[0m         )\n\u001b[1;32m    439\u001b[0m     )\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbindings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts=[doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings=embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "##store int he vector dtaabase\n",
    "vectorstore.add_documents(chunks,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cf410",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "252c66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "   def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "      \"\"\"\n",
    "      Intialize the retriever\n",
    "\n",
    "      Args:\n",
    "      vector_store: Vector store containing document embeddings\n",
    "      embedding_manager: Manager for generating query embeddings\n",
    "      \"\"\"\n",
    "      self.vector_store = vector_store\n",
    "      self.embedding_manager = embedding_manager\n",
    "\n",
    "   def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "      \"\"\"\n",
    "      Retrieve relevant documents based on a query\n",
    "\n",
    "      Args:\n",
    "      query: The query string to search for\n",
    "      top_k: The number of top results to return\n",
    "      score_threshold: Minimum similarity score threshold for results\n",
    "\n",
    "      Returns:\n",
    "      A list of dictionaries containing the retrieved documents and their scores\n",
    "      \"\"\"\n",
    "      print(f\"Retrieving documents for query: '{query}'\")\n",
    "      print(f\"Top K: {top_k}, Score Threshold: {score_threshold}\")\n",
    "\n",
    "      query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "      try:\n",
    "         results = self.vector_store.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "         )\n",
    "         \n",
    "         retrieved_docs = []\n",
    "         print(f\"total documents found: {len(results['documents'][0])}\")\n",
    "\n",
    "         if results['documents'] and results['documents'][0]:\n",
    "            documents = results['documents'][0]\n",
    "            metadatas = results['metadatas'][0]\n",
    "            distances = results['distances'][0]\n",
    "            ids = results['ids'][0]\n",
    "\n",
    "            for i, (doc_id, doc, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "               similarity_score = 1 - distance\n",
    "\n",
    "               print(f\"Document {i+1}: ID={doc_id}, Similarity Score={similarity_score}\")\n",
    "\n",
    "               if similarity_score >= score_threshold:\n",
    "                  retrieved_docs.append({\n",
    "                     'id': doc_id,\n",
    "                     'content': doc,\n",
    "                     'metadata': metadata,\n",
    "                     'similarity_score': similarity_score\n",
    "                  })\n",
    "            print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "         else:\n",
    "            print(\"No documents Found\")\n",
    "\n",
    "         return retrieved_docs\n",
    "            \n",
    "      except Exception as e:\n",
    "         print(f\"Error occurred while retrieving documents: {e}\")\n",
    "         return []\n",
    "      \n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18b5398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x16521e7a0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9251674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'Foundation AI'\n",
      "Top K: 5, Score Threshold: 0.0\n",
      "Generating embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "total documents found: 5\n",
      "Document 1: ID=doc_5e02bfa7_1, Similarity Score=-0.3005101680755615\n",
      "Document 2: ID=doc_499c6ae4_1, Similarity Score=-0.3005101680755615\n",
      "Document 3: ID=doc_1fbb6159_1, Similarity Score=-0.3005101680755615\n",
      "Document 4: ID=doc_76446591_1, Similarity Score=-0.3005101680755615\n",
      "Document 5: ID=doc_86e41453_3, Similarity Score=-0.48874354362487793\n",
      "Retrieved 0 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"Foundation AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87f503",
   "metadata": {},
   "source": [
    "### Integration Vectordb Context pipeline with LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c79fd87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_groq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Simple RAG pipeline with Groq LLM\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_groq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_groq'"
     ]
    }
   ],
   "source": [
    "### Simple RAG pipeline with Groq LLM\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM\n",
    "groq_api_key = \"\"\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"gemma2-9b-it\",temperature=0.1,max_tokens=1024)\n",
    "\n",
    "def rag_simple(query, retriever, llm, top_k= 3):\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    context = \"\\n \\n\".join([doc[\"content\"] for doc in results]) if results else \"\"\n",
    "\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "\n",
    "    prompt = f\"\"\"Use the following context to answer the question:\n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Question: {query}\n",
    "        \n",
    "        Answer:\"\"\"\n",
    "        \n",
    "    response = llm.invoke([prompt.format(context = context, query=query)])\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c8aa8",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dcc49a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m rag_advanced(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHard Negative Mining Technqiues\u001b[39m\u001b[38;5;124m\"\u001b[39m, rag_retriever, \u001b[43mllm\u001b[49m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, return_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSources:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msources\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"Hard Negative Mining Technqiues\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c59d9222",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 64\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m: question,\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m: answer_with_citations,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m     61\u001b[0m         }\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m adv_rag \u001b[38;5;241m=\u001b[39m AdvancedRAGPipeline(rag_retriever, \u001b[43mllm\u001b[49m)\n\u001b[1;32m     65\u001b[0m result \u001b[38;5;241m=\u001b[39m adv_rag\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is attention is all you need\u001b[39m\u001b[38;5;124m\"\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, summarize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Answer:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is attention is all you need\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96141822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_crash_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
